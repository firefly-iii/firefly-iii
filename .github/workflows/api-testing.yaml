name: Firefly III Test Suite

on:
  pull_request:
    branches:
      - main
      - intgrate_with_chatgpt
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - api
          - ai
          - webhook
          - business
      environment:
        description: 'Environment to test against'
        required: true
        default: 'staging'
        type: choice
        options:
          - development
          - staging
          - production

env:
  FIREFLY_BASE_URL: http://52.212.42.101:8080/api/v1
  FIREFLY_URL: http://52.212.42.101:8080
  FIREFLY_VERSION: fireflyiii/core:version-6.3.2
  FIREFLY_DB: mariaDB:noble
  FIREFLY_IMPORTER: fireflyiii/importer:version-1.7.10
  
jobs:
  unit-tests:
    name: Unit Tests (AI + Webhook)
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          repository: hamad-fyad/firefly
          token: ${{ secrets.UI_TESTING_GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Unit Tests (AI + Webhook)
        env:
          GITHUB_ACTIONS: true
          API_TESTING_TOKEN: ${{ secrets.API_TESTING_TOKEN }}
          STATIC_CRON_TOKEN: ${{ secrets.STATIC_CRON_TOKEN }}
        run: |
          python run_github_tests.py unit

      - name: Upload Unit Test Allure Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: allure-results-unit-${{ github.run_id }}
          path: allure-results/
          retention-days: 30

  api-tests:
    name: API Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    if: ${{ !cancelled() }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          repository: hamad-fyad/firefly
          token: ${{ secrets.UI_TESTING_GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Check Remote Firefly III Availability
        id: firefly_check
        run: |
          if curl -f -s --max-time 10 "${{ env.FIREFLY_URL }}/api/v1/about" > /dev/null; then
            echo "available=true" >> $GITHUB_OUTPUT
            echo "✅ Remote Firefly III instance is available"
          else
            echo "available=false" >> $GITHUB_OUTPUT
            echo "⚠️ Remote Firefly III instance is not available"
          fi

      - name: Run API Tests (if available)
        if: steps.firefly_check.outputs.available == 'true'
        env:
          GITHUB_ACTIONS: true
          FIREFLY_BASE_URL: ${{ env.FIREFLY_BASE_URL }}
          API_TESTING_TOKEN: ${{ secrets.API_TESTING_TOKEN }}
          STATIC_CRON_TOKEN: ${{ secrets.STATIC_CRON_TOKEN }}
        run: |
          python run_github_tests.py api

      - name: Run All Tests (fallback if API unavailable)
        if: steps.firefly_check.outputs.available == 'false'
        env:
          GITHUB_ACTIONS: true
          API_TESTING_TOKEN: ${{ secrets.API_TESTING_TOKEN }}
          STATIC_CRON_TOKEN: ${{ secrets.STATIC_CRON_TOKEN }}
        run: |
          echo "🔄 Remote Firefly III unavailable, running unit tests only"
          python run_github_tests.py unit

      - name: Upload API Test Allure Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: allure-results-api-${{ github.run_id }}
          path: allure-results/
          retention-days: 30

  comprehensive-tests:
    name: All Tests (Manual Trigger)
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.test_type == 'all'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          repository: hamad-fyad/firefly
          token: ${{ secrets.UI_TESTING_GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Comprehensive Test Suite
        env:
          GITHUB_ACTIONS: true
          FIREFLY_BASE_URL: ${{ env.FIREFLY_BASE_URL }}
          API_TESTING_TOKEN: ${{ secrets.API_TESTING_TOKEN }}
          STATIC_CRON_TOKEN: ${{ secrets.STATIC_CRON_TOKEN }}
        run: |
          python run_github_tests.py ${{ github.event.inputs.test_type }}

      - name: Upload Comprehensive Test Allure Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: allure-results-comprehensive-${{ github.run_id }}
          path: allure-results/
          retention-days: 30

  allure-report:
    name: Generate Test Reports
    runs-on: ubuntu-latest
    needs: [unit-tests, api-tests]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download previous Allure history
        uses: actions/download-artifact@v4
        with:
          name: allure-history-firefly
          path: allure-results/history
        continue-on-error: true

      - name: Download all Allure results
        uses: actions/download-artifact@v4
        with:
          pattern: allure-results-*-${{ github.run_id }}
          path: allure-results-downloaded
          merge-multiple: false

      - name: Merge Allure results
        run: |
          mkdir -p allure-results
          for dir in allure-results-downloaded/*/; do
            if [ -d "$dir" ]; then
              cp -r "$dir"* allure-results/ 2>/dev/null || true
            fi
          done
          
          # Create environment.properties for better reporting
          cat > allure-results/environment.properties << EOF
          Test.Suite=Firefly III Comprehensive Test Suite
          Environment=${{ github.event.inputs.environment || 'staging' }}
          Python.Version=3.11
          GitHub.Run=${{ github.run_id }}
          GitHub.Workflow=${{ github.workflow }}
          Firefly.URL=${{ env.FIREFLY_URL }}
          Test.Types=Unit Tests (AI + Webhook), API Integration Tests
          Timestamp=$(date -u +"%Y-%m-%d %H:%M:%S UTC")
          EOF

      - name: Generate Allure Report
        uses: simple-elf/allure-report-action@master
        with:
          allure_results: allure-results
          allure_report: allure-report-firefly
          gh_pages: gh-pages
          keep_reports: 3

      - name: Upload updated Allure history
        run: mkdir -p allure-results/history
      - uses: actions/upload-artifact@v4
        with:
          name: allure-history-firefly
          path: allure-results/history
          retention-days: 30

      - name: Deploy Allure report to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.UI_TESTING_GITHUB_TOKEN }}
          publish_dir: allure-report-firefly
          destination_dir: firefly-tests

      - name: Comment Test Results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.UI_TESTING_GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            
            // Check if allure-results directory exists and has test results
            let testSummary = "🧪 **Firefly III Test Results**\n\n";
            testSummary += `📊 **Test Report**: [View detailed results](https://hamad-fyad.github.io/firefly/firefly-tests/)\n\n`;
            
            // Add test type information
            testSummary += "### Tests Executed:\n";
            testSummary += "✅ **Unit Tests**: AI Categorizer & Webhook Service (16 tests)\n";
            testSummary += "🔌 **API Tests**: Firefly III Integration (depends on remote instance)\n\n";
            
            testSummary += "### Test Coverage:\n";
            testSummary += "- AI categorization logic with mocked OpenAI responses\n";
            testSummary += "- Webhook processing with payload validation\n";
            testSummary += "- Error handling and performance requirements\n";
            testSummary += "- API endpoints (if remote Firefly III is available)\n\n";
            
            testSummary += `🔗 **Workflow Run**: [#${{ github.run_id }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n`;
            testSummary += `📅 **Timestamp**: ${new Date().toISOString()}\n`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: testSummary
            });

# 📊 Test Reports: https://hamad-fyad.github.io/firefly/firefly-tests/
# 🚀 Workflow supports: Unit Tests (AI + Webhook), API Integration Tests, Business Workflows
# 🎯 Optimized for GitHub Actions with automatic fallback to unit tests if remote services unavailable